{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650d3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f8ab07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fdceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_images(directory):\n",
    "        image_array = None\n",
    "        scaler = StandardScaler()\n",
    "        for i in range(1, 40001):\n",
    "            image_path = f\"mdm_galaxy_training_{i}.png\"\n",
    "            f = os.path.join(directory, image_path)\n",
    "            img = Image.open(f)\n",
    "            #(n,h,w,1) is the preferred array shape for using a Keras CNN, where...\n",
    "            # n = number of observations\n",
    "            # h = image height\n",
    "            # w = image width\n",
    "            img_array = np.asarray(img).reshape(1,-1)\n",
    "            if type(image_array) == type(img_array) and image_array.shape[1]==img_array.shape[1]:\n",
    "                image_array = np.concatenate((image_array,img_array))\n",
    "                if image_array.shape[0]%500==0:\n",
    "                    print(\"Progress!\", image_array.shape)\n",
    "            else:\n",
    "                image_array = img_array\n",
    "                print('First image converted to numpy array. This message should only occur once')\n",
    "        image_array = scaler.fit_transform(image_array).reshape((image_array.shape[0],48,48,1))\n",
    "        \n",
    "        return image_array\n",
    "\n",
    "def star_images(directory):\n",
    "        image_array = None\n",
    "        scaler = StandardScaler()\n",
    "        for i in range(1, 40001):\n",
    "            image_path = f\"mdm_star_training_{i}.png\"\n",
    "            f = os.path.join(directory, image_path)\n",
    "            img = Image.open(f)\n",
    "            #(n,h,w,1) is the preferred array shape for using a Keras CNN, where...\n",
    "            # n = number of observations\n",
    "            # h = image height\n",
    "            # w = image width\n",
    "            img_array = np.asarray(img).reshape(1,-1)\n",
    "            if type(image_array) == type(img_array) and image_array.shape[1]==img_array.shape[1]:\n",
    "                image_array = np.concatenate((image_array,img_array))\n",
    "                if image_array.shape[0]%500==0:\n",
    "                    print(\"Progress!\", image_array.shape)\n",
    "            else:\n",
    "                image_array = img_array\n",
    "                print('First image converted to numpy array. This message should only occur once')\n",
    "        image_array = scaler.fit_transform(image_array).reshape((image_array.shape[0],48,48,1))\n",
    "        \n",
    "        return image_array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4f3982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image converted to numpy array. This message should only occur once\n",
      "Progress! (500, 2304)\n",
      "Progress! (1000, 2304)\n",
      "Progress! (1500, 2304)\n",
      "Progress! (2000, 2304)\n",
      "Progress! (2500, 2304)\n",
      "Progress! (3000, 2304)\n",
      "Progress! (3500, 2304)\n",
      "Progress! (4000, 2304)\n",
      "Progress! (4500, 2304)\n",
      "Progress! (5000, 2304)\n",
      "Progress! (5500, 2304)\n",
      "Progress! (6000, 2304)\n",
      "Progress! (6500, 2304)\n",
      "Progress! (7000, 2304)\n",
      "Progress! (7500, 2304)\n",
      "Progress! (8000, 2304)\n",
      "Progress! (8500, 2304)\n",
      "Progress! (9000, 2304)\n",
      "Progress! (9500, 2304)\n",
      "Progress! (10000, 2304)\n",
      "Progress! (10500, 2304)\n",
      "Progress! (11000, 2304)\n",
      "Progress! (11500, 2304)\n",
      "Progress! (12000, 2304)\n",
      "Progress! (12500, 2304)\n",
      "Progress! (13000, 2304)\n",
      "Progress! (13500, 2304)\n",
      "Progress! (14000, 2304)\n",
      "Progress! (14500, 2304)\n",
      "Progress! (15000, 2304)\n",
      "Progress! (15500, 2304)\n",
      "Progress! (16000, 2304)\n",
      "Progress! (16500, 2304)\n",
      "Progress! (17000, 2304)\n",
      "Progress! (17500, 2304)\n",
      "Progress! (18000, 2304)\n",
      "Progress! (18500, 2304)\n",
      "Progress! (19000, 2304)\n",
      "Progress! (19500, 2304)\n",
      "Progress! (20000, 2304)\n",
      "Progress! (20500, 2304)\n",
      "Progress! (21000, 2304)\n",
      "Progress! (21500, 2304)\n",
      "Progress! (22000, 2304)\n",
      "Progress! (22500, 2304)\n",
      "Progress! (23000, 2304)\n",
      "Progress! (23500, 2304)\n",
      "Progress! (24000, 2304)\n",
      "Progress! (24500, 2304)\n",
      "Progress! (25000, 2304)\n",
      "Progress! (25500, 2304)\n",
      "Progress! (26000, 2304)\n",
      "Progress! (26500, 2304)\n",
      "Progress! (27000, 2304)\n",
      "Progress! (27500, 2304)\n",
      "Progress! (28000, 2304)\n",
      "Progress! (28500, 2304)\n",
      "Progress! (29000, 2304)\n",
      "Progress! (29500, 2304)\n",
      "Progress! (30000, 2304)\n",
      "Progress! (30500, 2304)\n",
      "Progress! (31000, 2304)\n",
      "Progress! (31500, 2304)\n",
      "Progress! (32000, 2304)\n",
      "Progress! (32500, 2304)\n",
      "Progress! (33000, 2304)\n",
      "Progress! (33500, 2304)\n",
      "Progress! (34000, 2304)\n",
      "Progress! (34500, 2304)\n",
      "Progress! (35000, 2304)\n",
      "Progress! (35500, 2304)\n",
      "Progress! (36000, 2304)\n",
      "Progress! (36500, 2304)\n",
      "Progress! (37000, 2304)\n",
      "Progress! (37500, 2304)\n",
      "Progress! (38000, 2304)\n",
      "Progress! (38500, 2304)\n",
      "Progress! (39000, 2304)\n",
      "Progress! (39500, 2304)\n",
      "Progress! (40000, 2304)\n"
     ]
    }
   ],
   "source": [
    "training_images = galaxy_images(directory=\"C:/Users/Owner/Documents/GradSchool/Current/MachineLearning/Projects/mdm/mdm_images/galaxy_postage/training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdee478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(training_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f1a38b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image converted to numpy array. This message should only occur once\n",
      "Progress! (5000, 2304)\n",
      "Progress! (10000, 2304)\n",
      "Progress! (15000, 2304)\n",
      "Progress! (20000, 2304)\n",
      "Progress! (25000, 2304)\n",
      "Progress! (30000, 2304)\n",
      "Progress! (35000, 2304)\n",
      "Progress! (40000, 2304)\n"
     ]
    }
   ],
   "source": [
    "training_star_images = star_images(directory=\"C:/Users/Owner/Documents/GradSchool/Current/MachineLearning/Projects/mdm/mdm_images/star_postage/training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "175d39fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "(40000, 48, 48, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "training_y = np.asarray(pd.read_csv(\"C:/Users/Owner/Documents/GradSchool/Current/MachineLearning/Projects/mdm/mdm_training_solution_sorted.csv\")).astype('float32')[:,1:]\n",
    "print(training_y.shape)\n",
    "print(type(training_y))\n",
    "print(training_images.shape)\n",
    "print(type(training_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e07b8f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 33, 33, 8)         2056      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 16)        12816     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 8)         8200      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                148032    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 175,394\n",
      "Trainable params: 175,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(16, 16),activation='relu',input_shape=(48,48,1)))\n",
    "model.add(Conv2D(16, (10, 10), activation='relu'))\n",
    "model.add(Conv2D(8, (8, 8), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(LeakyReLU(alpha=0.1)) \n",
    "model.add(Dense(2, activation='linear'))\n",
    "\n",
    "model.compile(\n",
    "    loss=MeanSquaredError(),\n",
    "    optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1861be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 14s 4ms/step - loss: 9.9587e-04\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 5.4974e-04\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 5.4300e-04\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 5.2863e-04\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 5.1705e-04\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 5.0451e-04\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 4.9067e-04\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 4.9042e-04\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 4.9091e-04\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 4.7282e-04\n"
     ]
    }
   ],
   "source": [
    "model_trained = model.fit(\n",
    "    training_images,\n",
    "    training_y,\n",
    "    epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
